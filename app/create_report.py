import os
import json
from openai import OpenAI
from typing import List, Dict, Any

# --- âš™ï¸ 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
# ë³´ì•ˆì„ ìœ„í•´ API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# Colabì˜ ê²½ìš° Secretsì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY", ""))


# --- ğŸ“ 2. [ë³´ê³ ì„œ 1] ìš”ì•½ ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜ ---

def generate_summary_report(
    query: str, 
    web_docs: List[Dict], 
    db_docs: List[Dict], 
    approx_similar_count: int
) -> Dict[str, Any]:
    """
    ì•„ì´ë””ì–´ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ìš”ì•½ ë³´ê³ ì„œ(JSON)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ì‚¬ìš©ì ì•„ì´ë””ì–´ ì¿¼ë¦¬.
        web_docs (List[Dict]): ì›¹ ê²€ìƒ‰ ê²°ê³¼ (e.g., [{'title': ..., 'snippet': ...}]).
        db_docs (List[Dict]): ë‚´ë¶€ DB ê²€ìƒ‰ ê²°ê³¼ (e.g., [{'title': ..., 'content': ...}]).
        approx_similar_count (int): ì „ì²´ ìœ ì‚¬ ì‚¬ë¡€ ê±´ìˆ˜.

    Returns:
        Dict[str, Any]: GPTê°€ ìƒì„±í•œ ìš”ì•½ ë³´ê³ ì„œ JSON ê°ì²´.
    """
    # ì›¹ ë° DB ë¬¸ì„œ ì„¹ì…˜ êµ¬ì„±
    web_section = "\n\n".join([f"[WEB{i+1}] {doc.get('title', '')}\n{doc.get('snippet', '')}" for i, doc in enumerate(web_docs)])
    db_section = "\n\n".join([f"[DB{i+1}] {doc.get('title', '')}\n{doc.get('content', '')}" for i, doc in enumerate(db_docs)])
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì›ë³¸ ìœ ì§€)
    prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•™ìƒ ìŠ¤íƒ€íŠ¸ì—… ì•„ì´ë””ì–´ë¥¼ ì •ëŸ‰ì  ê¸°ì¤€ì— ë”°ë¼ í‰ê°€í•˜ê³ , ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤:
"{query}"

ìœ ì‚¬í•œ ì›¹ ë¬¸ì„œ:
{web_section}

ìœ ì‚¬í•œ ê³µëª¨ì „ ìˆ˜ìƒì‘ ë° ë‚´ë¶€ DB ì‚¬ë¡€:
{db_section}

ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ì•„ì´ë””ì–´ë¥¼ í‰ê°€í•˜ê³ , ê²°ê³¼ë¥¼ ì•„ë˜ì— ëª…ì‹œëœ JSON í˜•ì‹ ì˜ˆì‹œì— ì •í™•íˆ ë§ì¶° ì¶œë ¥í•´ ì£¼ì„¸ìš”.

[í‰ê°€ ê¸°ì¤€]
1.  total_similar_cases: ì›¹ ê²€ìƒ‰ ê²°ê³¼({approx_similar_count}ê±´)ì™€ DB ë¬¸ì„œ ìˆ˜ë¥¼ ì¢…í•©í•˜ì—¬ ì „ì²´ ìœ ì‚¬ ê±´ìˆ˜ë¥¼ ì •ìˆ˜ë¡œ íŒë‹¨.
2.  similarity: DB + ì›¹ ë¬¸ì„œ ê¸°ì¤€, ê¸°ìˆ ì  ì»¨ì…‰ì˜ ì¤‘ë³µì„±ì„ íŒë‹¨í•˜ì—¬ 0~100 ì‚¬ì´ ì •ìˆ˜ ê°’ìœ¼ë¡œ í‰ê°€.
3.  creativity: ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ì¡°í•©, ìƒˆë¡œì›€, ë‹¤ë¥¸ ëª©ì /ëŒ€ìƒ ì„¤ì • ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì—¬ 0~100 ì‚¬ì´ ì •ìˆ˜ ê°’ìœ¼ë¡œ í‰ê°€.
4.  feasibility: ê¸°ìˆ  ì„±ìˆ™ë„, ìƒìš©í™” ì—¬ë¶€, êµ¬í˜„ ë‚œì´ë„ ë“±ì„ ê³ ë ¤í•˜ì—¬ 0~100 ì‚¬ì´ ì •ìˆ˜ ê°’ìœ¼ë¡œ í‰ê°€.
5.  analysis_narrative: ìœ„ í‰ê°€ë¥¼ ì¢…í•©í•˜ì—¬ 600ì ë‚´ì™¸ì˜ ë¶„ì„ ìš”ì•½ì„ ë¬¸ìì—´ë¡œ ì‘ì„±.

[ì¶œë ¥ JSON í˜•ì‹ ì˜ˆì‹œ]
```json
{{
  "report_summary": {{
    "total_similar_cases": 19,
    "evaluation_scores": {{
      "similarity": 80,
      "creativity": 50,
      "feasibility": 50
    }},
    "analysis_narrative": "ê³µì¤‘ ëª¨ë¹Œë¦¬í‹° ë„ë©”ì¸ì˜ ë„ì‹¬ í†µê·¼ìš© ìˆ˜ì§ ì´ì°©ë¥™ ììœ¨ ë¹„í–‰ ì œì–´ í•˜ëŠ˜ ë¹„í–‰ ìë™ì°¨ ì•„ì´ë””ì–´ëŠ”, UAM/eVTOL ê´€ë ¨ ë‹¤ìˆ˜ ë¬¸í—Œê³¼ ìƒìš©í™” íë¦„ê³¼ ë†’ì€ ì¤‘ë³µì„±ì„ ë³´ì…ë‹ˆë‹¤. í•µì‹¬ ì»¨ì…‰(ë„ì‹¬ í†µê·¼, ìˆ˜ì§ ì´ì°©ë¥™, ììœ¨ ì œì–´)ì€ ê¸°ì¡´ ì—°êµ¬ì™€ ìƒë‹¹íˆ ê²¹ì¹˜ë‚˜, ëŒ€í•™ìƒ ìŠ¤íƒ€íŠ¸ì—…ì˜ ì°¨ë³„í™” í¬ì¸íŠ¸ê°€ ëª¨í˜¸í•©ë‹ˆë‹¤. ì‹¤í˜„ ê°€ëŠ¥ì„±ì€ ê¸°ìˆ  ì„±ìˆ™ë„ì™€ ê·œì œÂ·ì¸í”„ë¼ ì´ìŠˆë¡œ ì¸í•´ ë³´ìˆ˜ì ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤."
  }}
}}
```

ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSON ê°ì²´ë§Œ ìƒì„±í•˜ì„¸ìš”. ì´ì œ í‰ê°€ë¥¼ ì‹œì‘í•˜ì„¸ìš”.
"""
    try:
        response = client.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": prompt.strip()}]
        )
        report_str = response.choices[0].message.content.strip()
        return json.loads(report_str)
    except Exception as e:
        print(f"âš ï¸ [ìš”ì•½ ë³´ê³ ì„œ] GPT í˜¸ì¶œ ë˜ëŠ” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return {"error": str(e)}


# --- ğŸ“‘ 3. [ë³´ê³ ì„œ 2] ìƒì„¸ ì†ŒìŠ¤ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜ ---

def generate_detailed_sources_report(
    query: str, 
    web_docs: List[Dict], 
    db_docs: List[Dict]
) -> Dict[str, Any]:
    """
    ê° ìœ ì‚¬ ì‚¬ë¡€(ì†ŒìŠ¤)ë¥¼ ìƒì„¸íˆ ë¶„ì„í•˜ëŠ” ë³´ê³ ì„œ(JSON)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ì‚¬ìš©ì ì•„ì´ë””ì–´ ì¿¼ë¦¬.
        web_docs (List[Dict]): ì›¹ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸.
        db_docs (List[Dict]): ë‚´ë¶€ DB ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸.

    Returns:
        Dict[str, Any]: ìƒì„¸ ì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ JSON ê°ì²´.
    """
    # ì†ŒìŠ¤ ë¬¸ì„œ ë¸”ë¡ êµ¬ì„±
    def make_doc_block(docs: List[Dict], prefix: str) -> str:
        return "\n\n".join([
            f"[{prefix}{i+1}] Title: {doc.get('title', '')}\nContent: {doc.get('snippet') or doc.get('content', '')}\nLink: {doc.get('link', '')}\nScore: {doc.get('score', '')}"
            for i, doc in enumerate(docs)
        ])

    web_block = make_doc_block(web_docs, "WEB")
    db_block = make_doc_block(db_docs, "DB")

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì›ë³¸ ìœ ì§€)
    prompt = f"""
ë‹¹ì‹ ì€ ì°½ì—… ì•„ì´ë””ì–´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤:
"{query}"

ì•„ë˜ëŠ” ìœ„ ì•„ì´ë””ì–´ì™€ ê´€ë ¨ëœ ìœ ì‚¬ ìë£Œ ëª©ë¡ì…ë‹ˆë‹¤. ê° ìë£Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”.
---
[ìœ ì‚¬í•œ ì›¹ ë¬¸ì„œ]
{web_block}

[ìœ ì‚¬í•œ ê³µëª¨ì „ ìˆ˜ìƒì‘ ë° ë‚´ë¶€ DB ì‚¬ë¡€]
{db_block}
---

ê° ë¬¸ì„œì— ëŒ€í•´ ë‹¤ìŒ í•­ëª©ì„ JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í‰ê°€í•´ ì£¼ì„¸ìš”. ì›¹ ë¬¸ì„œëŠ” "web", DB ì‚¬ë¡€ëŠ” "internal_db"ë¡œ `source_type`ì„ ì§€ì •í•˜ì„¸ìš”.

[ì¶œë ¥ JSON í˜•ì‹]
```json
[
  {{
    "source_type": "web",
    "link": "Link í•„ë“œ ì°¸ê³ ",
    "thumbnail": null,
    "summary": "ì´ ì„œë¹„ìŠ¤ëŠ” XYZ ê¸°ìˆ ì„ í™œìš©í•´ ABC ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë‚´ìš©.",
    "score": "Score í•„ë“œ ì°¸ê³ í•˜ì—¬ ì •ìˆ˜ ë˜ëŠ” ì‹¤ìˆ˜ë¡œ ë³€í™˜",
    "insight": "ì´ ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ëŒ€ìƒ ì„¤ì • ë°©ì‹ì´ë‚˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì€ í˜„ì¬ ì•„ì´ë””ì–´ì— ì°¸ê³ í•  ë§Œí•¨."
  }},
  ...
]
```
ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSON ê°ì²´ë§Œ ìƒì„±í•˜ì„¸ìš”. ì´ì œ í‰ê°€ë¥¼ ì‹œì‘í•˜ì„¸ìš”.
"""
    try:
        response = client.chat.completions.create(
            model="gpt-5-nano", # ìµœì‹  ëª¨ë¸ ì‚¬ìš© ê¶Œì¥
            messages=[{"role": "user", "content": prompt.strip()}]
        )
        report_str = response.choices[0].message.content.strip()
        # GPTê°€ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°ì‹¸ëŠ” ê°ì²´ë¥¼ ë§Œë“¤ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ìœ ì—°í•˜ê²Œ íŒŒì‹±
        parsed_json = json.loads(report_str)
        if isinstance(parsed_json, dict) and len(parsed_json.keys()) == 1:
             # e.g., {"results": [...]} í˜•íƒœì¼ ê²½ìš°
            results_list = next(iter(parsed_json.values()))
        else:
            results_list = parsed_json
            
        return {"query": query, "detailed_results": results_list}

    except Exception as e:
        print(f"âš ï¸ [ìƒì„¸ ë³´ê³ ì„œ] GPT í˜¸ì¶œ ë˜ëŠ” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return {"query": query, "detailed_results": [], "error": str(e)}


# --- âœ… 4. ì˜ˆì‹œ ì‹¤í–‰ ---
# if __name__ == "__main__":
    # 1. ê°€ìƒ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ì›¹/DB ê²€ìƒ‰ ê²°ê³¼ê°€ ì´ ìœ„ì¹˜ì— ë“¤ì–´ê°‘ë‹ˆë‹¤)
    # user_query = "ë“œë¡ ì„ ì´ìš©í•œ ë„ì‹¬ ë‚´ ì†Œê·œëª¨ íƒë°° ë°°ì†¡ ì‹œìŠ¤í…œ"
    
    # mock_web_docs = [
        # {'title': 'ì•„ë§ˆì¡´, ë“œë¡  íƒë°° í”„ë¼ì„ ì—ì–´ ìƒìš©í™”', 'snippet': 'ì•„ë§ˆì¡´ì€ ë“œë¡ ì„ ì´ìš©í•œ íƒë°° ì„œë¹„ìŠ¤ í”„ë¼ì„ ì—ì–´ë¥¼ í†µí•´ 30ë¶„ ë‚´ ë°°ì†¡ì„ ëª©í‘œë¡œ í•˜ê³  ìˆë‹¤.', 'link': 'http://example.com/amazon', 'score': 0.92},
        # {'title': 'êµ­ë‚´ ìŠ¤íƒ€íŠ¸ì—…, ë“œë¡  ë¬¼ë¥˜ ì†”ë£¨ì…˜ìœ¼ë¡œ íˆ¬ì ìœ ì¹˜', 'snippet': 'êµ­ë‚´ì˜ í•œ ìŠ¤íƒ€íŠ¸ì—…ì´ ë“œë¡ ì„ í™œìš©í•œ ë¬¼ë¥˜ ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ ì‹œë¦¬ì¦ˆ A íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤.', 'link': 'http://example.com/startup', 'score': 0.88}]
    
    # mock_db_docs = [
        # {'title': 'ìº í¼ìŠ¤ ë‚´ ë„ì„œ ëŒ€ì¶œ ë°˜ë‚© ë“œë¡  ì‹œìŠ¤í…œ', 'content': 'êµë‚´ ë„ì„œê´€ê³¼ ê° ë‹¨ê³¼ëŒ€ ê±´ë¬¼ì„ ì‡ëŠ” ë“œë¡ ì„ í™œìš©í•˜ì—¬ í•™ìƒë“¤ì´ í¸ë¦¬í•˜ê²Œ ì±…ì„ ë¹Œë¦¬ê³  ë°˜ë‚©í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ì œì•ˆí•œë‹¤.', 'link': 'http://example.com/contest1', 'score': 0.95},
        # {'title': 'ì˜ì•½í’ˆ ê¸´ê¸‰ ë°°ì†¡ì„ ìœ„í•œ ë“œë¡  ë„¤íŠ¸ì›Œí¬', 'content': 'ì‚°ê°„ ì§€ì—­ì´ë‚˜ êµí†µ ì²´ì¦ì´ ì‹¬í•œ ë„ì‹¬ ì§€ì—­ì— ê¸´ê¸‰ ì˜ì•½í’ˆì„ ì‹ ì†í•˜ê²Œ ì „ë‹¬í•˜ê¸° ìœ„í•œ ë“œë¡  ë„¤íŠ¸ì›Œí¬ êµ¬ì¶• ì•„ì´ë””ì–´.', 'link': 'http://example.com/internal1', 'score': 0.91}]
    
    # mock_approx_similar_count = 25

    # print("=" * 50, flush = True)
    # print(f"ì‚¬ìš©ì ì•„ì´ë””ì–´: {user_query}", flush = True)
    # print("=" * 50, flush = True)

    # 2. ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ë° ì¶œë ¥
    # print("\n[1/2] ì •ëŸ‰ì  ìš”ì•½ ë³´ê³ ì„œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...", flush = True)
    # summary_report = generate_summary_report(
        # query=user_query,
        # web_docs=mock_web_docs,
        # db_docs=mock_db_docs,
        # approx_similar_count=mock_approx_similar_count
    # )
    # print(json.dumps(summary_report, indent=2, ensure_ascii=False), flush = True)

    # 3. ìƒì„¸ ì†ŒìŠ¤ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ë° ì¶œë ¥
    # print("\n[2/2] ìƒì„¸ ì†ŒìŠ¤ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...", flush = True)
    # detailed_report = generate_detailed_sources_report(
        # query=user_query,
        # web_docs=mock_web_docs,
        # db_docs=mock_db_docs
    # )
    # print(json.dumps(detailed_report, indent=2, ensure_ascii=False), flush = True)
