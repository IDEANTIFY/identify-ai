import os
import glob
import json
from typing import Dict, Optional, List
from datetime import datetime
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

class chatbot:
    # âœ¨ ë³€ê²½: memoryë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì…ë°›ë„ë¡ __init__ ìˆ˜ì •
    def __init__(self, report_path: str, user_info: Dict, structured_idea: Dict, openai_api_key: str, memory: ConversationBufferMemory):
        if not os.path.exists(report_path):
            raise FileNotFoundError(f"ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {report_path}")

        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        rag_context = self.create_context(report_path)
        system_prompt = self.create_system_prompt(rag_context, user_info, structured_idea)
        
        # 2. LangChain êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”
        llm = ChatOpenAI(model_name="gpt-5-nano", api_key=openai_api_key)
        
        self.memory = memory
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ë©”ëª¨ë¦¬ ë¡œë“œ í›„ ê°€ì¥ ì²˜ìŒì— ì¶”ê°€
        if not self.memory.chat_memory.messages:
            self.memory.chat_memory.add_message(SystemMessage(content=system_prompt))

        prompt = ChatPromptTemplate.from_messages([
            MessagesPlaceholder(variable_name="history"),
            ("human", "{user_input}"),
        ])

        # 3. ì²´ì¸ ìƒì„±
        self.chain = LLMChain(llm=llm, prompt=prompt, memory=self.memory)

        print(f"âœ… {user_info.get('name', 'ì‚¬ìš©ì')}ë‹˜ì„ ìœ„í•œ ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # âœ¨ ì¶”ê°€: ê³¼ê±° ëŒ€í™” ë¡œë“œ ì—¬ë¶€ ì•ˆë‚´
        if len(self.memory.chat_memory.messages) > 1:
            print("ğŸ’¬ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    def create_context(self, report_path: str) -> str:
        """ë¦¬í¬íŠ¸ íŒŒì¼ì—ì„œ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        with open(report_path, 'r', encoding='utf-8') as f:
            report_data = json.load(f)
        
        summary_report = report_data.get('summary_report', {}).get('report_summary', {})
        scores = summary_report.get('evaluation_scores', {})
        
        summary_context = (
            "## ì•„ì´ë””ì–´ ì¢…í•© ë¶„ì„ ìš”ì•½\n"
            f"- ì „ì²´ ìœ ì‚¬ ì‚¬ë¡€ ìˆ˜: {summary_report.get('total_similar_cases', 'N/A')}ê±´\n"
            f"- ì°½ì˜ì„± ì ìˆ˜: {scores.get('creativity', 'N/A')}/100\n"
            f"- ê¸°ìˆ  ì‹¤í˜„ ê°€ëŠ¥ì„± ì ìˆ˜: {scores.get('feasibility', 'N/A')}/100\n"
            f"\n### ì¢…í•© ì˜ê²¬\n{summary_report.get('analysis_narrative', 'N/A')}\n"
        )
        
        detailed_context = "\n## ğŸ“‘ ìœ ì‚¬ ì„œë¹„ìŠ¤ ìƒì„¸ ë¶„ì„\n"
        detailed_results = report_data.get('detailed_report', {}).get('detailed_results', [])
        for i, service in enumerate(detailed_results):
            detailed_context += (
                f"### [ìœ ì‚¬ ì„œë¹„ìŠ¤ {i+1}]\n"
                f"- ì œëª©: {service.get('title', 'N/A')}\n"
                f"- ìš”ì•½: {service.get('summary', 'N/A')}\n"
                f"- ì•„ì´ë””ì–´ ì°¸ê³ ì (Insight): {service.get('insight', 'N/A')}\n\n"
            )
        return summary_context + detailed_context

    def create_system_prompt(self, rag_context: str, user_info: Dict, structured_idea: Dict) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        user_info_str = "\n".join([f"- {key}: {value}" for key, value in user_info.items()])
        idea_str = "\n".join([f"- {key}: {value}" for key, value in structured_idea.items()])

        return f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ê³  ë°œì „ì‹œí‚¤ëŠ” 'ê°œì¸ ë§ì¶¤í˜• ìŠ¤íƒ€íŠ¸ì—… ë©˜í† 'ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì •ë³´, ì›ë³¸ ì•„ì´ë””ì–´, ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ê°œì¸í™”ëœ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” ì „ë¬¸ê°€ì˜ í†¤ì„ ìœ ì§€í•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ 'ì•¡ì…˜ ì•„ì´í…œ' ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”.

---
## ë©˜í† ë§ ëŒ€ìƒ ì‚¬ìš©ì ì •ë³´
{user_info_str}
---
## ì‚¬ìš©ìì˜ ì›ë³¸ ì•„ì´ë””ì–´
{idea_str}
---
## ì•„ì´ë””ì–´ ë¶„ì„ ë¦¬í¬íŠ¸ (RAG)
{rag_context}
---
"""

    def chat(self, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì±—ë´‡ì˜ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            response = self.chain.invoke({"user_input": user_input})
            return response.get('text', "ì˜¤ë¥˜: ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            return f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def save_history(self, user_name: str) -> None:
        """ëŒ€í™” ê¸°ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        save_dir = os.path.join(os.path.dirname(__file__), '..', 'dataset', 'chat_histories')
        os.makedirs(save_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        file_path = os.path.join(save_dir, f"history_{user_name}_{timestamp}.json")

        history_to_save = [
            {"role": msg.type, "content": msg.content}
            for msg in self.memory.chat_memory.messages
        ]

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(history_to_save, f, ensure_ascii=False, indent=4)
            print(f"âœ… ëŒ€í™” ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {file_path}")
        except Exception as e:
            print(f"âš ï¸ ëŒ€í™” ê¸°ë¡ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ğŸš€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def find_latest_file(directory: str, prefix: str) -> Optional[str]:
    """ì£¼ì–´ì§„ ë””ë ‰í† ë¦¬ì—ì„œ íŠ¹ì • ì ‘ë‘ì‚¬ë¥¼ ê°€ì§„ ê°€ì¥ ìµœì‹  íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    files = glob.glob(os.path.join(directory, f'{prefix}*.json'))
    return max(files, key=os.path.getctime) if files else None

def load_json_data(file_path: str) -> Optional[Dict]:
    """JSON íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not file_path or not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {file_path}")
        return None
    except Exception as e:
        print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
        
# âœ¨ ì¶”ê°€: ê³¼ê±° ëŒ€í™” ê¸°ë¡ì„ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def load_conversation_history(user_name: str) -> ConversationBufferMemory:
    """ì‚¬ìš©ìì˜ ìµœì‹  ëŒ€í™” ê¸°ë¡ì„ ì°¾ì•„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•©ë‹ˆë‹¤."""
    memory = ConversationBufferMemory(memory_key="history", return_messages=True)
    
    script_dir = os.path.dirname(__file__)
    history_dir = os.path.join(script_dir, '..', 'dataset', 'chat_histories')
    
    latest_history_file = find_latest_file(history_dir, f"history_{user_name}_")
    
    if latest_history_file:
        with open(latest_history_file, 'r', encoding='utf-8') as f:
            history_data = json.load(f)
            
        for message in history_data:
            role = message.get("role")
            content = message.get("content")
            if role == "human":
                memory.chat_memory.add_message(HumanMessage(content=content))
            elif role == "ai":
                memory.chat_memory.add_message(AIMessage(content=content))
            # SystemMessageëŠ” ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±í•˜ë¯€ë¡œ ë¶ˆëŸ¬ì˜¤ì§€ ì•ŠìŒ
    
    return memory

# --- ğŸš€ ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ---
if __name__ == '__main__':
    load_dotenv()
    
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()

    print("="*60)
    print("ğŸš€ ì±—ë´‡ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("="*60)

    script_dir = os.path.dirname(__file__)
    dataset_dir = os.path.join(script_dir, '..', 'dataset')
    
    user_info_file = os.path.join(dataset_dir, 'user_info.json')
    structured_idea_file = os.path.join(dataset_dir, 'structured_idea.json')
    report_file = find_latest_file(os.path.join(dataset_dir, 'reports'), 'report_total_')

    user_info = load_json_data(user_info_file)
    structured_idea = load_json_data(structured_idea_file)

    if user_info and structured_idea and report_file:
        try:
            user_name = user_info.get("name", "user")
            conversation_memory = load_conversation_history(user_name)

            bot = chatbot(
                report_path=report_file,
                user_info=user_info,
                structured_idea=structured_idea,
                openai_api_key=openai_key,
                memory=conversation_memory
            )
            print("\nì•ˆë…•í•˜ì„¸ìš”! ì•„ì´ë””ì–´ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")
            print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n")

            while True:
                user_question = input("You: ")
                if user_question.lower() in ['exit', 'quit']:
                    bot.save_history(user_name=user_name)
                    print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                print("\nMentor: ìƒê° ì¤‘...", end="", flush=True)
                response = bot.chat(user_question)
                print(f"\rMentor: {response}\n")

        except Exception as e:
            print(f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        print("âŒ ì±—ë´‡ ì‹¤í–‰ì— í•„ìš”í•œ íŒŒì¼(ì‚¬ìš©ì ì •ë³´, ì•„ì´ë””ì–´, ë¦¬í¬íŠ¸)ì„ ëª¨ë‘ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")