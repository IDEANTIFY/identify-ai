import os
import glob
import json
from typing import Dict, Optional
from datetime import datetime
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain_core.messages import SystemMessage

class chatbot:
    def __init__(self, report_path: str, user_info: Dict, structured_idea: Dict, openai_api_key: str):
        if not os.path.exists(report_path):
            raise FileNotFoundError(f"ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {report_path}")

        # 1. ì»¨í…ìŠ¤íŠ¸ ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        rag_context = self.create_context(report_path)
        system_prompt = self.create_system_prompt(rag_context, user_info, structured_idea)
        
        # 2. LangChain êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”
        llm = ChatOpenAI(model_name="gpt-5-nano", api_key=openai_api_key)
        
        self.memory = ConversationBufferMemory(memory_key="history", return_messages=True)
        self.memory.chat_memory.add_message(SystemMessage(content=system_prompt))

        prompt = ChatPromptTemplate.from_messages([
            MessagesPlaceholder(variable_name="history"),
            ("human", "{user_input}"),
        ])

        # 3. ì²´ì¸ ìƒì„±
        self.chain = LLMChain(llm=llm, prompt=prompt, memory=self.memory)

        print(f"âœ… {user_info.get('name', 'ì‚¬ìš©ì')}ë‹˜ì„ ìœ„í•œ ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def create_context(self, report_path: str) -> str:
        """ë¦¬í¬íŠ¸ íŒŒì¼ì—ì„œ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        with open(report_path, 'r', encoding='utf-8') as f:
            report_data = json.load(f)
        
        summary_report = report_data.get('summary_report', {}).get('report_summary', {})
        scores = summary_report.get('evaluation_scores', {})
        
        summary_context = (
            "## ì•„ì´ë””ì–´ ì¢…í•© ë¶„ì„ ìš”ì•½\n"
            f"- ì „ì²´ ìœ ì‚¬ ì‚¬ë¡€ ìˆ˜: {summary_report.get('total_similar_cases', 'N/A')}ê±´\n"
            f"- ì°½ì˜ì„± ì ìˆ˜: {scores.get('creativity', 'N/A')}/100\n"
            f"- ê¸°ìˆ  ì‹¤í˜„ ê°€ëŠ¥ì„± ì ìˆ˜: {scores.get('feasibility', 'N/A')}/100\n"
            f"\n### ì¢…í•© ì˜ê²¬\n{summary_report.get('analysis_narrative', 'N/A')}\n"
        )
        
        detailed_context = "\n## ğŸ“‘ ìœ ì‚¬ ì„œë¹„ìŠ¤ ìƒì„¸ ë¶„ì„\n"
        detailed_results = report_data.get('detailed_report', {}).get('detailed_results', [])
        for i, service in enumerate(detailed_results):
            detailed_context += (
                f"### [ìœ ì‚¬ ì„œë¹„ìŠ¤ {i+1}]\n"
                f"- ì œëª©: {service.get('title', 'N/A')}\n"
                f"- ìš”ì•½: {service.get('summary', 'N/A')}\n"
                f"- ì•„ì´ë””ì–´ ì°¸ê³ ì (Insight): {service.get('insight', 'N/A')}\n\n"
            )
        return summary_context + detailed_context

    def create_system_prompt(self, rag_context: str, user_info: Dict, structured_idea: Dict) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        user_info_str = "\n".join([f"- {key}: {value}" for key, value in user_info.items()])
        idea_str = "\n".join([f"- {key}: {value}" for key, value in structured_idea.items()])

        return f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ê³  ë°œì „ì‹œí‚¤ëŠ” 'ê°œì¸ ë§ì¶¤í˜• ìŠ¤íƒ€íŠ¸ì—… ë©˜í† 'ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì •ë³´, ì›ë³¸ ì•„ì´ë””ì–´, ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ê°œì¸í™”ëœ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” ì „ë¬¸ê°€ì˜ í†¤ì„ ìœ ì§€í•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ 'ì•¡ì…˜ ì•„ì´í…œ' ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”.

---
## ë©˜í† ë§ ëŒ€ìƒ ì‚¬ìš©ì ì •ë³´
{user_info_str}
---
## ì‚¬ìš©ìì˜ ì›ë³¸ ì•„ì´ë””ì–´
{idea_str}
---
## ì•„ì´ë””ì–´ ë¶„ì„ ë¦¬í¬íŠ¸ (RAG)
{rag_context}
---
"""

    def chat(self, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì±—ë´‡ì˜ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            response = self.chain.invoke({"user_input": user_input})
            return response.get('text', "ì˜¤ë¥˜: ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            return f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def save_history(self, user_name: str) -> None:
        """ëŒ€í™” ê¸°ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        save_dir = os.path.join(os.path.dirname(__file__), '..', 'dataset', 'chat_histories')
        os.makedirs(save_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        file_path = os.path.join(save_dir, f"history_{user_name}_{timestamp}.json")

        history_to_save = [
            {"role": msg.type, "content": msg.content}
            for msg in self.memory.chat_memory.messages
        ]

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(history_to_save, f, ensure_ascii=False, indent=4)
            print(f"âœ… ëŒ€í™” ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {file_path}")
        except Exception as e:
            print(f"âš ï¸ ëŒ€í™” ê¸°ë¡ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ğŸš€ í…ŒìŠ¤íŠ¸ ë° ì‚¬ìš© ì˜ˆì‹œ ---
def find_latest_report() -> Optional[str]:
    """ê°€ì¥ ìµœê·¼ì˜ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    script_dir = os.path.dirname(__file__)
    reports_dir = os.path.join(script_dir, '..', 'dataset', 'reports')
    report_files = glob.glob(os.path.join(reports_dir, 'report_total_*.json'))
    return max(report_files, key=os.path.getctime) if report_files else None

if __name__ == '__main__':
    load_dotenv()
    
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()

    print("="*60)
    print("ğŸš€ ì±—ë´‡ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("="*60)

    sample_user_info = {
        "name": "êµ¬ì¤€íšŒ",
        "major": "AIë¹…ë°ì´í„°ìœµí•©ê²½ì˜í•™ê³¼",
        "interests": ["LLM ê°œë°œ", "Persona LLM ê°œë°œ"]
    }
    sample_structured_idea = {
              "ì£¼ìš” ë‚´ìš©": "AI ê¸°ë°˜ ì‹ë‹¨ ë¶„ì„ ë° ë§ì¶¤í˜• ë ˆì‹œí”¼ ì¶”ì²œ ëª¨ë°”ì¼ ì•±",
              "ë„ë©”ì¸": "ê±´ê°• ë° í”¼íŠ¸ë‹ˆìŠ¤, í‘¸ë“œí…Œí¬",
              "ëª©ì ": "ê°œì¸ ë§ì¶¤í˜• ê±´ê°• ê´€ë¦¬ ë° ì‹ìŠµê´€ ê°œì„ ",
              "ì°¨ë³„ì„±": "AIë¥¼ í™œìš©í•œ ìë™ ì‹ë‹¨ ë¶„ì„ ë° ì •ë°€í•œ ë ˆì‹œí”¼ ì¶”ì²œ",
              "í•µì‹¬ ê¸°ìˆ ": "ì¸ê³µì§€ëŠ¥(AI), ë¨¸ì‹ ëŸ¬ë‹, ì´ë¯¸ì§€ ì¸ì‹(ìŒì‹ ì‚¬ì§„ ë¶„ì„)",
              "ì„œë¹„ìŠ¤ ëŒ€ìƒ": "ê±´ê°•ì— ê´€ì‹¬ì´ ë§ì€ ì‚¬ìš©ì, íŠ¹ì • ì‹ë‹¨ì´ í•„ìš”í•œ í™˜ì"
          }
    
    report_file = find_latest_report()
    if report_file:
        try:
            bot = chatbot(
                report_path=report_file,
                user_info=sample_user_info,
                structured_idea=sample_structured_idea,
                openai_api_key=openai_key
            )
            print("\nì•ˆë…•í•˜ì„¸ìš”! ì•„ì´ë””ì–´ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")
            print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n")

            while True:
                user_question = input("You: ")
                if user_question.lower() in ['exit', 'quit']:
                    bot.save_history(user_name=sample_user_info.get("name", "user"))
                    print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                print("\nMentor: ìƒê° ì¤‘...", end="", flush=True)
                response = bot.chat(user_question)
                print(f"\rMentor: {response}\n")

        except Exception as e:
            print(f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ë¦¬í¬íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")