## chat_idea_report.py.py

import os
import glob
import json
from typing import Dict, Optional, List
from datetime import datetime
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

from utils.file_utils import load_json, find_latest_file
from utils.memory_manager import load_memory
from utils.history_manager import save_history


class IdeaReportChatbot:
    def __init__(self, report_path: str, user_info: Dict, structured_idea: Dict, openai_api_key: str, memory: ConversationBufferMemory = None):
        if not os.path.exists(report_path):
            raise FileNotFoundError(f"ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {report_path}")

        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        rag_context = self.create_context(report_path)
        system_prompt = self.create_system_prompt(rag_context, user_info, structured_idea)
        
        # 2. LangChain êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(model_name="gpt-5-nano", api_key=openai_api_key)
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ë©”ëª¨ë¦¬ ë¡œë“œ í›„ ê°€ì¥ ì²˜ìŒì— ì¶”ê°€
        user_name = user_info.get("name", "user")
        self.memory = memory if memory else load_memory(
            user_name=user_name,
            system_prompt=system_prompt)

        prompt = ChatPromptTemplate.from_messages([
            MessagesPlaceholder(variable_name="history"),
            ("human", "{user_input}"),
        ])

        # 3. ì²´ì¸ ìƒì„±
        self.chain = LLMChain(llm=self.llm, prompt=prompt, memory=self.memory)

        print(f"âœ… {user_info.get('name', 'ì‚¬ìš©ì')}ë‹˜ì„ ìœ„í•œ ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # âœ¨ ì¶”ê°€: ê³¼ê±° ëŒ€í™” ë¡œë“œ ì—¬ë¶€ ì•ˆë‚´
        if len(self.memory.chat_memory.messages) > 1:
            print("ğŸ’¬ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    def create_context(self, report_path: str) -> str:
        """ë¦¬í¬íŠ¸ íŒŒì¼ì—ì„œ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        with open(report_path, 'r', encoding='utf-8') as f:
            report_data = json.load(f)
        
        summary_report = report_data.get('summary_report', {}).get('report_summary', {})
        scores = summary_report.get('evaluation_scores', {})
        
        summary_context = (
            "## ì•„ì´ë””ì–´ ì¢…í•© ë¶„ì„ ìš”ì•½\n"
            f"- ì „ì²´ ìœ ì‚¬ ì‚¬ë¡€ ìˆ˜: {summary_report.get('total_similar_cases', 'N/A')}ê±´\n"
            f"- ì°½ì˜ì„± ì ìˆ˜: {scores.get('creativity', 'N/A')}/100\n"
            f"- ê¸°ìˆ  ì‹¤í˜„ ê°€ëŠ¥ì„± ì ìˆ˜: {scores.get('feasibility', 'N/A')}/100\n"
            f"\n### ì¢…í•© ì˜ê²¬\n{summary_report.get('analysis_narrative', 'N/A')}\n"
        )
        
        detailed_context = "\n## ğŸ“‘ ìœ ì‚¬ ì„œë¹„ìŠ¤ ìƒì„¸ ë¶„ì„\n"
        detailed_results = report_data.get('detailed_report', {}).get('detailed_results', [])
        for i, service in enumerate(detailed_results):
            detailed_context += (
                f"### [ìœ ì‚¬ ì„œë¹„ìŠ¤ {i+1}]\n"
                f"- ì œëª©: {service.get('title', 'N/A')}\n"
                f"- ìš”ì•½: {service.get('summary', 'N/A')}\n"
                f"- ì•„ì´ë””ì–´ ì°¸ê³ ì (Insight): {service.get('insight', 'N/A')}\n\n"
            )
        return summary_context + detailed_context

    def create_system_prompt(self, rag_context: str, user_info: Dict, structured_idea: Dict) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        user_info_str = "\n".join([f"- {key}: {value}" for key, value in user_info.items()])
        idea_str = "\n".join([f"- {key}: {value}" for key, value in structured_idea.items()])

        return f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ê³  ë°œì „ì‹œí‚¤ëŠ” 'ê°œì¸ ë§ì¶¤í˜• ìŠ¤íƒ€íŠ¸ì—… ë©˜í† 'ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì •ë³´, ì›ë³¸ ì•„ì´ë””ì–´, ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ê°œì¸í™”ëœ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” ì „ë¬¸ê°€ì˜ í†¤ì„ ìœ ì§€í•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ 'ì•¡ì…˜ ì•„ì´í…œ' ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”.

---
## ë©˜í† ë§ ëŒ€ìƒ ì‚¬ìš©ì ì •ë³´
{user_info_str}
---
## ì‚¬ìš©ìì˜ ì›ë³¸ ì•„ì´ë””ì–´
{idea_str}
---
## ì•„ì´ë””ì–´ ë¶„ì„ ë¦¬í¬íŠ¸ (RAG)
{rag_context}
---
"""

    def chat(self, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì±—ë´‡ì˜ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            response = self.chain.invoke({"user_input": user_input})
            return response.get('text', "ì˜¤ë¥˜: ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            return f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def save_history(self, user_name: str):
        """ëŒ€í™” ê¸°ë¡ ì €ì¥"""
        save_history(user_name, self.memory.chat_memory.messages)

# --- ğŸš€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def find_latest_file(directory: str, prefix: str) -> Optional[str]:
    """ì£¼ì–´ì§„ ë””ë ‰í† ë¦¬ì—ì„œ íŠ¹ì • ì ‘ë‘ì‚¬ë¥¼ ê°€ì§„ ê°€ì¥ ìµœì‹  íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    files = glob.glob(os.path.join(directory, f'{prefix}*.json'))
    return max(files, key=os.path.getctime) if files else None


# --- ğŸš€ ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ---
if __name__ == '__main__':
    load_dotenv()
    
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()

    print("="*60)
    print("ğŸš€ ì±—ë´‡ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("="*60)

    dataset_dir = os.path.join(os.path.dirname(__file__), "..", "dataset")
    user_info = load_json(os.path.join(dataset_dir, "user_info.json"))
    structured_idea = load_json(os.path.join(dataset_dir, "structured_idea.json"))
    report_file = find_latest_file(os.path.join(dataset_dir, "reports"), "report_total_")

    if user_info and structured_idea and report_file:
        try:
            user_name = user_info.get("name", "user")
            bot = IdeaReportChatbot(
                report_path=report_file,
                user_info=user_info,
                structured_idea=structured_idea,
                openai_api_key=openai_key,
            )
            print("\nì•ˆë…•í•˜ì„¸ìš”! ì•„ì´ë””ì–´ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")
            print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n")

            while True:
                user_question = input("You: ")
                if user_question.lower() in ['exit', 'quit']:
                    bot.save_history(user_name=user_name)
                    print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                print("\nMentor: ìƒê° ì¤‘...", end="", flush=True)
                response = bot.chat(user_question)
                print(f"\rMentor: {response}\n")

        except Exception as e:
            print(f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        print("âŒ ì±—ë´‡ ì‹¤í–‰ì— í•„ìš”í•œ íŒŒì¼(ì‚¬ìš©ì ì •ë³´, ì•„ì´ë””ì–´, ë¦¬í¬íŠ¸)ì„ ëª¨ë‘ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")